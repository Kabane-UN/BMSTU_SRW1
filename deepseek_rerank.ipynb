{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98193d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from scipy.stats import kendalltau\n",
    "from sklearn.metrics import ndcg_score\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92ff6126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query-id</th>\n",
       "      <th>corpus-id</th>\n",
       "      <th>e5-score</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>599</td>\n",
       "      <td>83.478034</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>91397</td>\n",
       "      <td>83.293903</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>140938</td>\n",
       "      <td>83.293903</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>9725</td>\n",
       "      <td>83.293903</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>598</td>\n",
       "      <td>83.043307</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10675</th>\n",
       "      <td>558</td>\n",
       "      <td>188549</td>\n",
       "      <td>84.378934</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10676</th>\n",
       "      <td>558</td>\n",
       "      <td>188527</td>\n",
       "      <td>84.362769</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10677</th>\n",
       "      <td>558</td>\n",
       "      <td>188537</td>\n",
       "      <td>84.205627</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10678</th>\n",
       "      <td>558</td>\n",
       "      <td>188543</td>\n",
       "      <td>84.190488</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10679</th>\n",
       "      <td>558</td>\n",
       "      <td>188516</td>\n",
       "      <td>84.135640</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10680 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       query-id  corpus-id   e5-score  score\n",
       "0             0        599  83.478034      1\n",
       "1             0      91397  83.293903      0\n",
       "2             0     140938  83.293903      0\n",
       "3             0       9725  83.293903      0\n",
       "4             0        598  83.043307      1\n",
       "...         ...        ...        ...    ...\n",
       "10675       558     188549  84.378934      0\n",
       "10676       558     188527  84.362769      0\n",
       "10677       558     188537  84.205627      0\n",
       "10678       558     188543  84.190488      0\n",
       "10679       558     188516  84.135640      0\n",
       "\n",
       "[10680 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = pd.read_json(\"corpus.jsonl\", lines=True)\n",
    "queries = pd.read_json(\"queries.jsonl\", lines=True)\n",
    "corpus.set_index(\"_id\", inplace=True)\n",
    "queries.set_index(\"_id\", inplace=True)\n",
    "top_qrels = pd.read_csv(\"top_qrels.tsv\", sep=\"\\t\")\n",
    "top_qrels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06e75623",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_name = \"grok_fact\"\n",
    "full_name = f\"deepseek_{prompt_name}.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c7d3f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepseek_df = pd.read_csv(full_name, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e7e13c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_scores_llm(e5_df, llm):\n",
    "  merged = pd.merge(\n",
    "        e5_df,\n",
    "        llm,\n",
    "        on=['query-id', 'corpus-id'],\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "  del merged[\"human-score\"]\n",
    "  \n",
    "  return merged\n",
    "ftop_qrels = merge_scores_llm(top_qrels, deepseek_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcaac731",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepSeekJudge:\n",
    "  def __init__(self):\n",
    "    self.client = OpenAI(api_key=\"sk-21cb3976392646d687940daed0ca3650\", base_url=\"https://api.deepseek.com\")\n",
    "  def generate_judgement(self, query, passage):\n",
    "    system_message = \"\"\"\n",
    "Вы — строгая система оценки релевантности для информационного поиска. \n",
    "Ваша единственная задача — определить, насколько отрывок подтверждает или содержит факт, заявленный в запросе.\n",
    "\n",
    "Используйте только целочисленную шкалу от 0 до 2:\n",
    "\n",
    "2 = Отрывок полностью содержит и явно подтверждает весь факт из запроса (прямое и полное соответствие).\n",
    "1 = Отрывок содержит только часть факта, косвенно на него намекает или подтверждает лишь отдельные элементы.\n",
    "0 = Отрывок не содержит никаких элементов факта или полностью нерелевантен.\n",
    "\n",
    "Отвечайте ИСКЛЮЧИТЕЛЬНО одним JSON-объектом вида {\"score\": N}, где N — 0, 1 или 2.\n",
    "Никаких пояснений, комментариев, дополнительного текста, кавычек или форматирования вне JSON не допускается.\n",
    "\"\"\"\n",
    "    user_message_template = f\"\"\"\n",
    "Запрос: {query}\n",
    "\n",
    "Отрывок: {passage}\n",
    "\n",
    "Оцените релевантность по шкале 0–2 и верните только JSON {{\"score\": N}}.\n",
    "\"\"\"\n",
    "    response = self.client.chat.completions.create(\n",
    "      model=\"deepseek-chat\",\n",
    "      messages=[\n",
    "          {\"role\": \"system\", \"content\": system_message},\n",
    "          {\"role\": \"user\", \"content\": user_message_template},\n",
    "      ],\n",
    "      stream=False,\n",
    "      response_format={\n",
    "        'type': 'json_object'\n",
    "      }\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "805ef76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "judge = DeepSeekJudge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab47cfa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10680/10680 [3:54:21<00:00,  1.32s/it] \n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for idx, row in tqdm(ftop_qrels.iterrows(), total=len(ftop_qrels)):\n",
    "  true_score = row[\"score\"]\n",
    "  llm_score = row[\"llm-score\"]\n",
    "  if pd.isna(llm_score):\n",
    "    query = queries.loc[row[\"query-id\"]][\"text\"]\n",
    "    response = corpus.loc[row[\"corpus-id\"]][\"text\"]\n",
    "    res = judge.generate_judgement(query, response)\n",
    "    res = json.loads(res)\n",
    "    llm_score = res[\"score\"]\n",
    "  result = {\n",
    "    \"llm-score\": llm_score,\n",
    "    \"human-score\": true_score,\n",
    "    \"query-id\": row[\"query-id\"],\n",
    "    \"corpus-id\": row[\"corpus-id\"]\n",
    "  }\n",
    "  results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e87fd2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3454476800697558"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "llm = results_df[\"llm-score\"].to_numpy(int)\n",
    "human = results_df[\"human-score\"].to_numpy(int)\n",
    "cohen_kappa_score(llm, human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fab6986c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG:  0.801798988360169\n",
      "NRMSE:  0.31182980568790375\n",
      "NMAE:  0.1555243445692884\n",
      "kendalltau:  0.5307825137841512\n",
      "RBO:  0.6334445293125055\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import metrics\n",
    "\n",
    "\n",
    "print(\"NDCG: \", metrics.calc_ndcg(results_df))\n",
    "print(\"NRMSE: \", metrics.calc_nrmse(results_df))\n",
    "print(\"NMAE: \", metrics.calc_nmae(results_df))\n",
    "print(\"kendalltau: \", metrics.calc_kendalltau(results_df))\n",
    "print(\"RBO: \", metrics.calc_rbo(results_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01e9968b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results_df).to_csv(f\"rerank_{full_name}\", sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
