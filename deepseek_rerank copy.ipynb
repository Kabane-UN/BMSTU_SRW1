{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98193d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from scipy.stats import kendalltau\n",
    "from sklearn.metrics import ndcg_score\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92ff6126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query-id</th>\n",
       "      <th>corpus-id</th>\n",
       "      <th>e5-score</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>599</td>\n",
       "      <td>83.478034</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>91397</td>\n",
       "      <td>83.293903</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>140938</td>\n",
       "      <td>83.293903</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>9725</td>\n",
       "      <td>83.293903</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>598</td>\n",
       "      <td>83.043307</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10675</th>\n",
       "      <td>558</td>\n",
       "      <td>188549</td>\n",
       "      <td>84.378934</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10676</th>\n",
       "      <td>558</td>\n",
       "      <td>188527</td>\n",
       "      <td>84.362769</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10677</th>\n",
       "      <td>558</td>\n",
       "      <td>188537</td>\n",
       "      <td>84.205627</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10678</th>\n",
       "      <td>558</td>\n",
       "      <td>188543</td>\n",
       "      <td>84.190488</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10679</th>\n",
       "      <td>558</td>\n",
       "      <td>188516</td>\n",
       "      <td>84.135640</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10680 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       query-id  corpus-id   e5-score  score\n",
       "0             0        599  83.478034      1\n",
       "1             0      91397  83.293903      0\n",
       "2             0     140938  83.293903      0\n",
       "3             0       9725  83.293903      0\n",
       "4             0        598  83.043307      1\n",
       "...         ...        ...        ...    ...\n",
       "10675       558     188549  84.378934      0\n",
       "10676       558     188527  84.362769      0\n",
       "10677       558     188537  84.205627      0\n",
       "10678       558     188543  84.190488      0\n",
       "10679       558     188516  84.135640      0\n",
       "\n",
       "[10680 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = pd.read_json(\"corpus.jsonl\", lines=True)\n",
    "queries = pd.read_json(\"queries.jsonl\", lines=True)\n",
    "corpus.set_index(\"_id\", inplace=True)\n",
    "queries.set_index(\"_id\", inplace=True)\n",
    "top_qrels = pd.read_csv(\"top_qrels.tsv\", sep=\"\\t\")\n",
    "top_qrels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06e75623",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_name = \"gemini_fact\"\n",
    "full_name = f\"deepseek_{prompt_name}.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c7d3f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepseek_df = pd.read_csv(full_name, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e7e13c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_scores_llm(e5_df, llm):\n",
    "  merged = pd.merge(\n",
    "        e5_df,\n",
    "        llm,\n",
    "        on=['query-id', 'corpus-id'],\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "  del merged[\"human-score\"]\n",
    "  \n",
    "  return merged\n",
    "ftop_qrels = merge_scores_llm(top_qrels, deepseek_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcaac731",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepSeekJudge:\n",
    "  def __init__(self):\n",
    "    self.client = OpenAI(api_key=\"sk-21cb3976392646d687940daed0ca3650\", base_url=\"https://api.deepseek.com\")\n",
    "  def generate_judgement(self, query, passage):\n",
    "    system_message = \"\"\"\n",
    "Ты — строгий эксперт по проверке фактов и оценке семантической релевантности. Твоя задача — проанализировать запрос и отрывок текста, чтобы определить, насколько отрывок подтверждает или содержит информацию из запроса.\n",
    "\n",
    "Используй следующую шкалу для оценки (целое число от 0 до 2):\n",
    "\n",
    "[2] Полностью релевантный: Отрывок содержит исчерпывающую информацию, подтверждающую весь факт из запроса. Смысл запроса полностью раскрыт в тексте.\n",
    "[1] Частично релевантный: Отрывок касается темы запроса, упоминает ключевые сущности или содержит часть факта, но не дает полного подтверждения или ответа.\n",
    "[0] Нерелевантный: Отрывок не имеет отношения к запросу, не содержит упоминаний ключевых объектов или противоречит контексту.\n",
    "\n",
    "ВАЖНО:\n",
    "1. Твой ответ должен быть СТРОГО в формате JSON.\n",
    "2. Используй ключ \"score\".\n",
    "3. Значение должно быть только числом: 0, 1 или 2.\n",
    "4. Не пиши никаких пояснений, комментариев или вводных слов. Только JSON.\n",
    "\n",
    "Пример формата ответа:\n",
    "{\"score\": 1}\n",
    "\"\"\"\n",
    "    user_message_template = f\"\"\"\n",
    "Оцени релевантность следующей пары текстов, используя заданные критерии.\n",
    "\n",
    "ЗАПРОС:\n",
    "{query}\n",
    "\n",
    "ОТРЫВОК:\n",
    "{passage}\n",
    "\n",
    "Выведи оценку в JSON формате: {{\"score\": N}}\n",
    "\"\"\"\n",
    "    response = self.client.chat.completions.create(\n",
    "      model=\"deepseek-chat\",\n",
    "      messages=[\n",
    "          {\"role\": \"system\", \"content\": system_message},\n",
    "          {\"role\": \"user\", \"content\": user_message_template},\n",
    "      ],\n",
    "      stream=False,\n",
    "      response_format={\n",
    "        'type': 'json_object'\n",
    "      }\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "805ef76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "judge = DeepSeekJudge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab47cfa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10680/10680 [3:58:28<00:00,  1.34s/it] \n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for idx, row in tqdm(ftop_qrels.iterrows(), total=len(ftop_qrels)):\n",
    "  true_score = row[\"score\"]\n",
    "  llm_score = row[\"llm-score\"]\n",
    "  if pd.isna(llm_score):\n",
    "    query = queries.loc[row[\"query-id\"]][\"text\"]\n",
    "    response = corpus.loc[row[\"corpus-id\"]][\"text\"]\n",
    "    res = judge.generate_judgement(query, response)\n",
    "    res = json.loads(res)\n",
    "    llm_score = res[\"score\"]\n",
    "  result = {\n",
    "    \"llm-score\": llm_score,\n",
    "    \"human-score\": true_score,\n",
    "    \"query-id\": row[\"query-id\"],\n",
    "    \"corpus-id\": row[\"corpus-id\"]\n",
    "  }\n",
    "  results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e87fd2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30646262912063527"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "llm = results_df[\"llm-score\"].to_numpy(int)\n",
    "human = results_df[\"human-score\"].to_numpy(int)\n",
    "cohen_kappa_score(llm, human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fab6986c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG:  0.8032047888429822\n",
      "NRMSE:  0.332149113664127\n",
      "NMAE:  0.1821629213483146\n",
      "kendalltau:  0.5127738609288442\n",
      "RBO:  0.6092175609049182\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import metrics\n",
    "\n",
    "\n",
    "print(\"NDCG: \", metrics.calc_ndcg(results_df))\n",
    "print(\"NRMSE: \", metrics.calc_nrmse(results_df))\n",
    "print(\"NMAE: \", metrics.calc_nmae(results_df))\n",
    "print(\"kendalltau: \", metrics.calc_kendalltau(results_df))\n",
    "print(\"RBO: \", metrics.calc_rbo(results_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01e9968b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results_df).to_csv(f\"rerank_{full_name}\", sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
