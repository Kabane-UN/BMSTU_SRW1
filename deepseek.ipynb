{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44b05ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from scipy.stats import kendalltau\n",
    "from sklearn.metrics import ndcg_score\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19f07c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query-id</th>\n",
       "      <th>corpus-id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bwq-0</td>\n",
       "      <td>bwc-9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bwq-1</td>\n",
       "      <td>bwc-73</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bwq-1</td>\n",
       "      <td>bwc-70</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bwq-1</td>\n",
       "      <td>bwc-78</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bwq-2</td>\n",
       "      <td>bwc-653</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1550</th>\n",
       "      <td>bwq-534</td>\n",
       "      <td>bwc-166896</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551</th>\n",
       "      <td>bwq-534</td>\n",
       "      <td>bwc-166918</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1552</th>\n",
       "      <td>bwq-534</td>\n",
       "      <td>bwc-166919</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553</th>\n",
       "      <td>bwq-534</td>\n",
       "      <td>bwc-166923</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1554</th>\n",
       "      <td>bwq-535</td>\n",
       "      <td>bwc-167035</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1555 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     query-id   corpus-id  score\n",
       "0       bwq-0       bwc-9      2\n",
       "1       bwq-1      bwc-73      1\n",
       "2       bwq-1      bwc-70      2\n",
       "3       bwq-1      bwc-78      2\n",
       "4       bwq-2     bwc-653      2\n",
       "...       ...         ...    ...\n",
       "1550  bwq-534  bwc-166896      2\n",
       "1551  bwq-534  bwc-166918      1\n",
       "1552  bwq-534  bwc-166919      2\n",
       "1553  bwq-534  bwc-166923      1\n",
       "1554  bwq-535  bwc-167035      2\n",
       "\n",
       "[1555 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = pd.read_json(\"corpus.jsonl\", lines=True)\n",
    "queries = pd.read_json(\"queries.jsonl\", lines=True)\n",
    "corpus.set_index(\"_id\", inplace=True)\n",
    "queries.set_index(\"_id\", inplace=True)\n",
    "qrels = pd.read_csv(\"top_qrels.tsv\", sep=\"\\t\")\n",
    "qrels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c6d768a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepSeekJudge:\n",
    "  def __init__(self):\n",
    "    self.client = OpenAI(api_key=\"sk-21cb3976392646d687940daed0ca3650\", base_url=\"https://api.deepseek.com\")\n",
    "  def generate_judgement(self, query, passage):\n",
    "    system_message = \"\"\"\n",
    "Ты — строгий эксперт по проверке фактов и оценке семантической релевантности. Твоя задача — проанализировать запрос и отрывок текста, чтобы определить, насколько отрывок подтверждает или содержит информацию из запроса.\n",
    "\n",
    "Используй следующую шкалу для оценки (целое число от 0 до 2):\n",
    "\n",
    "[2] Полностью релевантный: Отрывок содержит исчерпывающую информацию, подтверждающую весь факт из запроса. Смысл запроса полностью раскрыт в тексте.\n",
    "[1] Частично релевантный: Отрывок касается темы запроса, упоминает ключевые сущности или содержит часть факта, но не дает полного подтверждения или ответа.\n",
    "[0] Нерелевантный: Отрывок не имеет отношения к запросу, не содержит упоминаний ключевых объектов или противоречит контексту.\n",
    "\n",
    "ВАЖНО:\n",
    "1. Твой ответ должен быть СТРОГО в формате JSON.\n",
    "2. Используй ключ \"score\".\n",
    "3. Значение должно быть только числом: 0, 1 или 2.\n",
    "4. Не пиши никаких пояснений, комментариев или вводных слов. Только JSON.\n",
    "\n",
    "Пример формата ответа:\n",
    "{\"score\": 1}\n",
    "\"\"\"\n",
    "    user_message_template = f\"\"\"\n",
    "Оцени релевантность следующей пары текстов, используя заданные критерии.\n",
    "\n",
    "ЗАПРОС:\n",
    "{query}\n",
    "\n",
    "ОТРЫВОК:\n",
    "{passage}\n",
    "\n",
    "Выведи оценку в JSON формате: {{\"score\": N}}\n",
    "\"\"\"\n",
    "    response = self.client.chat.completions.create(\n",
    "      model=\"deepseek-chat\",\n",
    "      messages=[\n",
    "          {\"role\": \"system\", \"content\": system_message},\n",
    "          {\"role\": \"user\", \"content\": user_message_template},\n",
    "      ],\n",
    "      stream=False,\n",
    "      response_format={\n",
    "        'type': 'json_object'\n",
    "      }\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ec6dcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "judge = DeepSeekJudge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d1b1d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:45<00:00,  1.65s/it]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "test = qrels.head(100)\n",
    "for idx, row in tqdm(test.iterrows(), total=len(test)):\n",
    "  true_score = row[\"score\"]\n",
    "  query = queries.loc[row[\"query-id\"]][\"text\"]\n",
    "  response = corpus.loc[row[\"corpus-id\"]][\"text\"]\n",
    "  res = judge.generate_judgement(query, response)\n",
    "  res = json.loads(res)\n",
    "  result = {\n",
    "    \"llm-score\": res[\"score\"],\n",
    "    \"human-score\": true_score,\n",
    "    \"query-id\": row[\"query-id\"],\n",
    "    \"corpus-id\": row[\"corpus-id\"]\n",
    "\n",
    "  }\n",
    "  results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74a03817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.039548022598870025"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "llm = results_df[\"llm-score\"].to_numpy(int)\n",
    "human = results_df[\"human-score\"].to_numpy(int)\n",
    "cohen_kappa_score(llm, human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba1561f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG:  0.9861071634012046\n",
      "NRMSE:  0.47958315233127197\n",
      "NMAE:  0.38\n",
      "kendalltau:  0.5329382517914113\n",
      "RBO:  0.2570461955999999\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import metrics\n",
    "\n",
    "\n",
    "print(\"NDCG: \", metrics.calc_ndcg(results_df))\n",
    "print(\"NRMSE: \", metrics.calc_nrmse(results_df))\n",
    "print(\"NMAE: \", metrics.calc_nmae(results_df))\n",
    "print(\"kendalltau: \", metrics.calc_kendalltau(results_df))\n",
    "print(\"RBO: \", metrics.calc_rbo(results_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "434aa3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results_df).to_csv('sents_llm_deepseek_gemini_fact.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1633860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0],\n",
       "       [30, 10,  0],\n",
       "       [ 8, 30, 22]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "llm = results_df[\"llm-score\"].to_numpy(int)\n",
    "human = results_df[\"human-score\"].to_numpy(int)\n",
    "confusion_matrix(human, llm, labels=range(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ec62d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM:  1 HUMAN:  2 ID:  bwq-1\n",
      "Query:  Обидевшись, старший брат записал дисс на младшего .\n",
      "Passage:  Оригинальная версия трека содержала критику, направленную в адрес младшего брата Майкла Джексона.\n",
      "LLM:  1 HUMAN:  2 ID:  bwq-2\n",
      "Query:  « Ваня » , пройдясь по Британии , обрушился ледяным дождём на юг России .\n",
      "Passage:  В России влияние циклона больше всего ощутили на юге европейской части.\n",
      "LLM:  1 HUMAN:  2 ID:  bwq-2\n",
      "Query:  « Ваня » , пройдясь по Британии , обрушился ледяным дождём на юг России .\n",
      "Passage:  В Ростове-на-Дону 12 декабря из-за ледяного дождя, который, с небольшими перерывами, шёл пять дней, остановили движение общественного транспорта, а 13 декабря в школах отменили занятия.\n",
      "LLM:  1 HUMAN:  2 ID:  bwq-3\n",
      "Query:  Охота на « врагов народа », начавшаяся после убийства Кирова , не делала скидок на возраст преследуемых .\n",
      "Passage:  После его убийства был введён упрощённый порядок ведения следствия; смертные приговоры приводились в исполнения в течение 24-х часов.\n",
      "LLM:  1 HUMAN:  2 ID:  bwq-4\n",
      "Query:  Данте поместил внука английского короля на седьмой круг Ада .\n",
      "Passage:  Это преступление побудило Данте в «Божественной комедии» поместить Ги де Монфора в число убийц в седьмом круге Ада.\n",
      "LLM:  1 HUMAN:  2 ID:  bwq-5\n",
      "Query:  В итальянских школах изучают балладу о солдате, не сумевшем выстрелить во врага.\n",
      "Passage:  Главный недостаток состоит в том, что какой-то умник включил её в школьные учебники, так что дети с раннего возраста приучились её ненавидеть — ведь им, возможно, пришлось учить её наизусть.\n",
      "LLM:  1 HUMAN:  2 ID:  bwq-7\n",
      "Query:  Для борьбы с вредителями леса используют деревья .\n",
      "Passage:  В качестве ловчих деревьев используются ослабленные и малоценные деревья, а также свежий ветровал, бурелом и заготовленный лесоматериал.\n",
      "LLM:  1 HUMAN:  2 ID:  bwq-10\n",
      "Query:  Конструктор космических кораблей любил работать, стоя на голове.\n",
      "Passage:  Особенности Фаже слыл эсцентриком: в любую погоду носил гавайские рубахи и любил делать стойку на голове во время технических совещаний.\n",
      "LLM:  1 HUMAN:  2 ID:  bwq-11\n",
      "Query:  Шутер от первого лица по « Южному Парку », несмотря на плохой приём критиков, стал одной из самых продаваемых игр для Nintendo 64 .\n",
      "Passage:  Уже в январе 1999 года, Acclaim сообщила о том, что объемы продаж превзошли все их ожидания, а сама игра возглавила список самых продаваемых игр для Nintendo 64.\n",
      "LLM:  1 HUMAN:  2 ID:  bwq-11\n",
      "Query:  Шутер от первого лица по « Южному Парку », несмотря на плохой приём критиков, стал одной из самых продаваемых игр для Nintendo 64 .\n",
      "Passage:  Шутер от первого лица, выпущен для PC, Nintendo 64 и Sony PlayStation.\n",
      "LLM:  1 HUMAN:  2 ID:  bwq-12\n",
      "Query:  Тело папы римского дважды эксгумировали , один раз судили ( на илл. ) и трижды хоронили.\n",
      "Passage:  Тело Формоза эксгумировали, одели в папское облачение и поместили на сидение.\n",
      "LLM:  1 HUMAN:  2 ID:  bwq-12\n",
      "Query:  Тело папы римского дважды эксгумировали , один раз судили ( на илл. ) и трижды хоронили.\n",
      "Passage:  После этого его похоронили на иноземном кладбище, возможно, из-за интердикта Иоанна VIII, запрещавшего Формозу возвращаться в Рим, но через некоторое время труп был вырыт, вероятно, сторонниками Стефана VI, и брошен в реку Тибр.\n",
      "LLM:  1 HUMAN:  2 ID:  bwq-14\n",
      "Query:  Последний роман Джейн Остин пришлось дописывать сценаристам сериала .\n",
      "Passage:  Создатели сериала использовали сюжетный материал от Остин только в первых эпизодах, а в дальнейшем сами продолжили историю созданных писательницей персонажей.\n",
      "LLM:  1 HUMAN:  2 ID:  bwq-15\n",
      "Query:  Европейцы уже несколько столетий вкушают суп из майских жуков .\n",
      "Passage:  История и описание До середины XX века суп из майских жуков готовили в Германии и Франции.\n",
      "LLM:  1 HUMAN:  2 ID:  bwq-15\n",
      "Query:  Европейцы уже несколько столетий вкушают суп из майских жуков .\n",
      "Passage:  Считается, что в Германии традиция приготовления блюда прослеживается уже со Средних веков.\n",
      "LLM:  1 HUMAN:  2 ID:  bwq-16\n",
      "Query:  Сериал о приходе нацистов к власти в США был создан из-за избрания президентом страны Дональда Трампа .\n",
      "Passage:  Однако после выборов 2016 года, на которых президентом США был избран Дональд Трамп, Саймон признал книгу Рот актуальной аллегорией, решил экранизировать её и предложил своему давнему коллеге Эду Бёрнсу совместно написать сценарий.\n",
      "LLM:  1 HUMAN:  2 ID:  bwq-19\n",
      "Query:  Объединитель Японии был вынужден вспороть себе живот из-за труднообъяснимого мятежа ( на илл. ) .\n",
      "Passage:  Харакири (яп. 腹切り), или сэппуку (яп. 切腹) (букв. «вспарывание живота»), — ритуальное самоубийство методом вспарывания живота, принятое среди самурайского сословия средневековой Японии.\n",
      "LLM:  1 HUMAN:  2 ID:  bwq-19\n",
      "Query:  Объединитель Японии был вынужден вспороть себе живот из-за труднообъяснимого мятежа ( на илл. ) .\n",
      "Passage:  Он взял храм штурмом, и Нобунага, охраняемый только небольшим числом телохранителей и слуг, был вынужден совершить харакири.\n",
      "LLM:  1 HUMAN:  2 ID:  bwq-20\n",
      "Query:  По мнению Джона Леннона , « Эй, Джуд! » можно интерпретировать как «Эй, Джон!».\n",
      "Passage:  Хотя изначально Маккартни написал «Hey Jude» для Джулиана, Леннон думал, что на самом деле она была написана для него.\n",
      "LLM:  1 HUMAN:  2 ID:  bwq-22\n",
      "Query:  Длинные вбрасывания мяча крикетистом вынудили англичан изменить футбольные правила .\n",
      "Passage:  Ганн был высоким (по разным данным, от 190 до 195 см) и длинноруким, обладая способностью вбрасывать мяч с огромных дистанций, практически через всё футбольное поле.\n",
      "LLM:  1 HUMAN:  2 ID:  bwq-24\n",
      "Query:  Создавая роман о Партенопейской республике , Александр Дюма мстил за отца .\n",
      "Passage:  Литературоведы констатируют, что в этой книге писатель сводил старые счёты с сицилийскими Бурбонами, которых считал своими личными врагами.\n",
      "LLM:  1 HUMAN:  2 ID:  bwq-24\n",
      "Query:  Создавая роман о Партенопейской республике , Александр Дюма мстил за отца .\n",
      "Passage:  Его отец Тома-Александр Дюма, генерал французской армии, попал в плен к неаполитанцам в 1799 году, когда возвращался из Египта, два года провёл в заключении, пережил попытку отравления и вернулся домой с подорванным здоровьем, из-за чего умер в возрасте 43 лет (будущему писателю тогда было всего три года).\n",
      "LLM:  1 HUMAN:  2 ID:  bwq-25\n",
      "Query:  В известной советской военной песне использована мелодия вальса , который, вероятно, играли на борту тонущего « Титаника ».\n",
      "Passage:  Особенно известен тем обстоятельством, что, вероятно, именно его играл оркестр под управлением Уоллеса Хартли во время катастрофы «Титаника», чтобы успокоить пассажиров.\n",
      "LLM:  1 HUMAN:  2 ID:  bwq-25\n",
      "Query:  В известной советской военной песне использована мелодия вальса , который, вероятно, играли на борту тонущего « Титаника ».\n",
      "Passage:  Учитывая это обстоятельство, а также ряд других фактов, Франкофор пришёл к выводу: «…я понял, что этот вальс, возможно, играли на „Титанике“, в частности, в момент его гибели.\n",
      "LLM:  1 HUMAN:  2 ID:  bwq-31\n",
      "Query:  Предновогодний шлягер из « Карнавальной ночи » был создан автором гимна Латвийской ССР .\n",
      "Passage:  Заслуженный деятель искусств Латвийской ССР (1945 год), автор музыки гимна Латвийской ССР (1944).\n",
      "LLM:  1 HUMAN:  2 ID:  bwq-31\n",
      "Query:  Предновогодний шлягер из « Карнавальной ночи » был создан автором гимна Латвийской ССР .\n",
      "Passage:  Там он принял участие в конкурсе по написанию музыки гимна Латвийской ССР, на котором победил и стал автором музыки Государственного гимна Латвийской ССР (стихи Ф. Я. Рокпелниса и Ю. Ванага).\n",
      "LLM:  1 HUMAN:  2 ID:  bwq-32\n",
      "Query:  Германо-скандинавский бог и его кабан особо почитались под Новый год.\n",
      "Passage:  На общегерманском празднике Иоль, посвящённом Фрейру, который отмечался во время середины зимы, вепрь приносился в жертву, чтобы новый год стал счастливым.\n",
      "LLM:  1 HUMAN:  2 ID:  bwq-35\n",
      "Query:  Популярный аниме-персонаж похож на известного японского актёра .\n",
      "Passage:  Наследие Необычная причёска и другие внешние черты персонажа Мацуды в «Тантэй-моногатари» послужили вдохновением при создании главного персонажа аниме и манги Cowboy Bebop — Спайка Шпигеля.\n",
      "LLM:  1 HUMAN:  2 ID:  bwq-37\n",
      "Query:  Пираты и негры — это часть истории Абхазии.\n",
      "Passage:  Абхазские пираты — известный феномен в Средневековье, активно орудовавшие на территории Чёрного моря пираты из Абхазии.\n",
      "LLM:  1 HUMAN:  2 ID:  bwq-37\n",
      "Query:  Пираты и негры — это часть истории Абхазии.\n",
      "Passage:  Чёрные абхазы (кавказские негры) — небольшая расово-этническая ассимилированная негроидная группа абхазского народа африканского происхождения, проживающая преимущественно в абхазском селении Адзюбжа в устье реки Кодор и окрестных сёлах Абхазии (Члоу, Поквеш, Агдарра, Меркула и некоторых других).\n"
     ]
    }
   ],
   "source": [
    "res = results_df[(results_df['llm-score'] == 1) & (results_df['human-score'] == 2)]\n",
    "\n",
    "for _, row in res.iterrows():\n",
    "  print(\"LLM: \", row[\"llm-score\"], \"HUMAN: \", row[\"human-score\"], \"ID: \", row[\"query-id\"])\n",
    "  print(\"Query: \", queries.loc[row[\"query-id\"]][\"text\"])\n",
    "  print(\"Passage: \", corpus.loc[row[\"corpus-id\"]][\"text\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
